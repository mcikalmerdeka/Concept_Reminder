Source : https://claude.ai/chat/57b8790f-ff81-4a78-b0de-fb255ce3bc05

-----------------------------------------------------------
I'll explain the key differences between Pearson correlation and linear regression, focusing on their coefficients and interpretations, then provide the complete reference code.

**Pearson Correlation vs Linear Regression: Key Differences**

1. Pearson Correlation (r):
- Measures strength and direction of linear relationship
- Formula: r = Σ((x - x̄)(y - ȳ)) / √(Σ(x - x̄)² * Σ(y - ȳ)²)
- Range: -1 to +1
- Interpretation:
  * -1: Perfect negative correlation
  * 0: No linear correlation
  * +1: Perfect positive correlation
  * Sign indicates direction
  * Magnitude indicates strength

2. Linear Regression:
- Finds best-fitting line through points (y = mx + b)
- R-squared (R²) = r²
- Formula: R² = 1 - (Σ(y - ŷ)²) / (Σ(y - ȳ)²)
  where ŷ is predicted y, ȳ is mean of y
- Range: 0 to 1 (always positive)
- Interpretation:
  * Proportion of variance in y explained by x
  * 0: Model explains none of the variability
  * 1: Model explains all variability
  * Example: R² = 0.64 means 64% of variance explained

**Relationship between r and R²**:
- R² is square of Pearson's r
- R² removes negative signs
- Example: r = -0.8 → R² = 0.64
- Both measure relationship strength but interpret differently

Here's the complete reference code comparing all methods:

```python
import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns

# Create sample data
data = pd.DataFrame({
    'x': [1, 2, 3, 4, 5],
    'y': [2, 4, 5, 4, 5]
})
x = data['x']
y = data['y']

# 1. Using pandas correlation
pearson_pandas = x.corr(y)

# 2. Using scipy.stats pearsonr
pearson_scipy = stats.pearsonr(x, y)
# pearson_scipy[0] is r, pearson_scipy[1] is p-value

# 3. Using numpy corrcoef
pearson_numpy = np.corrcoef(x, y)[0,1]

# 4. Using linear regression
linregress_result = stats.linregress(x, y)

# Print all results
print("=== Correlation Coefficients (r) ===")
print(f"Pandas correlation: {pearson_pandas:.6f}")
print(f"Scipy pearsonr: {pearson_scipy[0]:.6f}")
print(f"Scipy p-value: {pearson_scipy[1]:.6f}")
print(f"Numpy corrcoef: {pearson_numpy:.6f}")
print(f"Linregress r-value: {linregress_result.rvalue:.6f}")

print("\n=== Linear Regression Results ===")
print(f"R-squared (R²): {linregress_result.rvalue**2:.6f}")
print(f"Slope: {linregress_result.slope:.6f}")
print(f"Intercept: {linregress_result.intercept:.6f}")
print(f"P-value: {linregress_result.pvalue:.6f}")
print(f"Standard error: {linregress_result.stderr:.6f}")

# Visualize the relationship
plt.figure(figsize=(12, 5))

# Scatter plot with regression line
plt.subplot(1, 2, 1)
sns.regplot(x='x', y='y', data=data, scatter_kws={'s': 50})
plt.title(f'Regression Line\nr = {pearson_pandas:.3f}, R² = {linregress_result.rvalue**2:.3f}')

# Correlation heatmap
plt.subplot(1, 2, 2)
sns.heatmap(data.corr(), annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Correlation Heatmap')

plt.tight_layout()
plt.show()

# Real-world example with interpretation
sales_data = pd.DataFrame({
    'advertising': [10, 15, 20, 25, 30, 35, 40],
    'sales': [100, 120, 150, 170, 190, 210, 250]
})

regression = stats.linregress(sales_data['advertising'], sales_data['sales'])

print("\n=== Real-world Example Interpretation ===")
print(f"Correlation coefficient (r): {regression.rvalue:.3f}")
print(f"R-squared (R²): {regression.rvalue**2:.3f}")
print(f"Slope: {regression.slope:.2f}")
print("\nInterpretation:")
print(f"1. Correlation (r) = {regression.rvalue:.3f}:")
print(f"   - Shows a strong positive linear relationship")
print(f"   - As advertising increases, sales tend to increase")
print(f"\n2. R-squared (R²) = {regression.rvalue**2:.3f}:")
print(f"   - {(regression.rvalue**2*100):.1f}% of variance in sales is explained by advertising")
print(f"   - Remaining {((1-regression.rvalue**2)*100):.1f}% is due to other factors")
print(f"\n3. Regression equation:")
print(f"   Sales = {regression.slope:.2f} × Advertising + {regression.intercept:.2f}")
print(f"   - For each unit increase in advertising, sales increase by {regression.slope:.2f} units")
print(f"\n4. Statistical significance:")
print(f"   - P-value: {regression.pvalue:.6f}")
print(f"   - Relationship is {'statistically significant' if regression.pvalue < 0.05 else 'not statistically significant'}")
```

This code provides:
1. Implementation of all correlation calculation methods
2. Complete linear regression analysis
3. Visualization of the relationship
4. Real-world example with interpretation
5. Statistical significance testing

The key takeaway is that while both Pearson correlation (r) and R² measure relationship strength, they serve different purposes:
- r tells you about direction and strength
- R² tells you about explained variance
- Linear regression provides additional information about the relationship (slope, intercept, p-value)